{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning and Artificial Intelligence (MScA 32017)\n",
    "\n",
    "# Project: Detection of Toxic Comments Online\n",
    "\n",
    "# Introduction\n",
    "[Jigsaw's Toxic Comment ClassificationChallenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge), organized by Kaggle and [Jigsaw](https://jigsaw.google.com/) attracted more than 4500 teams and appeared the third most popular featured contest in Kaggle history. The goal of the competition was to identify and classify toxic online comments.  \n",
    "\n",
    "As Kaggle puts it, \"The Conversation AI team, a research initiative founded by Jigsaw and Google (both a part of Alphabet) are working on tools to help improve online conversation. Discussing things we care about can be difficult. The threat of abuse and harassment online means that many people stop expressing themselves and give up on seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut user comments\". \n",
    "\n",
    "# Data overview\n",
    "\n",
    "Train and test data can be found on the [data page](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data). Log in to kaggle.com web site and download files:\n",
    "\n",
    "`train.csv`, `test.csv`, `test_labels.csv`.\n",
    "\n",
    "Look at the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\zjx04\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\zjx04\\anaconda3\\lib\\site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\zjx04\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\zjx04\\anaconda3\\lib\\site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: six in c:\\users\\zjx04\\anaconda3\\lib\\site-packages (from h5py->keras) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\zjx04\\anaconda3\\lib\\site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\zjx04\\anaconda3\\lib\\site-packages (from keras) (1.18.1)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\zjx04\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Dense,\\\n",
    "    GlobalMaxPooling1D, LSTM, Bidirectional\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\zjx04\\\\Jupython_WD\\\\Advanced_ML'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Steps\n",
    "\n",
    "#### Import the Pre-Trained Word Vectors\n",
    "\n",
    "#### Link - http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSION = 100\n",
    "EMBEDDING_FILE_LOC = './Project3_Text/glove.6B.' + str(EMBEDDING_DIMENSION) + 'd.txt'\n",
    "TRAINING_DATA_LOC = 'tc_train.csv'\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(TRAINING_DATA_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 400000 word vectors are found.\n"
     ]
    }
   ],
   "source": [
    "word_to_vector = {}\n",
    "with open(EMBEDDING_FILE_LOC, encoding=\"utf8\") as file:\n",
    "    # A space-separated text file in the format\n",
    "    # word vec[0] vec[1] vec[2] ...\n",
    "    for line in file:\n",
    "        word = line.split()[0]\n",
    "        word_vec = line.split()[1:]\n",
    "\n",
    "        # converting word_vec into numpy array\n",
    "        # adding it in the word_to_vector dictionary\n",
    "        word_to_vector[word] = np.asarray(word_vec, dtype='float32')\n",
    "\n",
    "    # print the total words found\n",
    "    print(f'Total of {len(word_to_vector)} word vectors are found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 223549 entries, 0 to 223548\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             223549 non-null  object\n",
      " 1   comment_text   223549 non-null  object\n",
      " 2   toxic          223549 non-null  int64 \n",
      " 3   severe_toxic   223549 non-null  int64 \n",
      " 4   obscene        223549 non-null  int64 \n",
      " 5   threat         223549 non-null  int64 \n",
      " 6   insult         223549 non-null  int64 \n",
      " 7   identity_hate  223549 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking the data info for any null entries present\n",
    "training_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contain columns of id, text comment and 6 columns of class indicators which are the target variables.\n",
    "\n",
    "The target variables are the following types of toxicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "types = list(training_data)[1:]\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data into Feature (Comment) and Target Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = training_data['comment_text'].values\n",
    "detection_classes = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']\n",
    "target_classes = training_data[detection_classes].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments can belong to several classes simultaneously. The following figure shows frequences of the classes in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of the comments 5000\n",
      "Minimum length of the comments 1\n",
      "Median length of the comments 203\n"
     ]
    }
   ],
   "source": [
    "# Max and Min Length\n",
    "print(f'Maximum length of the comments {max(len(s) for s in comments)}')\n",
    "print(f'Minimum length of the comments {min(len(s) for s in comments)}')\n",
    "\n",
    "# Median Length\n",
    "s = sorted(len(s) for s in comments)\n",
    "print(f'Median length of the comments {s[len(s) // 2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Comments (Strings) into Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(comments)\n",
    "sequences = tokenizer.texts_to_sequences(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word to Integer Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300257 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_to_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding Sequences to a N x T Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (223549, 100)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Form the embedding matrix\n",
    "\n",
    "#### Preparation of Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_VOCAB_SIZE, len(word_to_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIMENSION))\n",
    "for word, i in word_to_index.items():\n",
    "    if i < MAX_VOCAB_SIZE:\n",
    "        embedding_vector = word_to_vector.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "# words not found in embedding index will be all zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Pre-Trained Word Embeddings into an Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIMENSION,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Bidirectional LSTM Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = embedding_layer(input_)\n",
    "x = Bidirectional(LSTM(units=15, return_sequences=True))(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "output = Dense(len(detection_classes), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(input_, output)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Bidirectional LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1398/1398 [==============================] - 197s 141ms/step - loss: 0.1002 - accuracy: 0.9045 - val_loss: 0.0825 - val_accuracy: 0.9818\n",
      "Epoch 2/10\n",
      "1398/1398 [==============================] - 217s 155ms/step - loss: 0.0613 - accuracy: 0.9919 - val_loss: 0.0757 - val_accuracy: 0.9769\n",
      "Epoch 3/10\n",
      "1398/1398 [==============================] - 179s 128ms/step - loss: 0.0567 - accuracy: 0.9910 - val_loss: 0.0684 - val_accuracy: 0.9904\n",
      "Epoch 4/10\n",
      "1398/1398 [==============================] - 406s 290ms/step - loss: 0.0540 - accuracy: 0.9909 - val_loss: 0.0683 - val_accuracy: 0.9786\n",
      "Epoch 5/10\n",
      "1398/1398 [==============================] - 501s 358ms/step - loss: 0.0524 - accuracy: 0.9897 - val_loss: 0.0655 - val_accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "1398/1398 [==============================] - 426s 305ms/step - loss: 0.0509 - accuracy: 0.9854 - val_loss: 0.0684 - val_accuracy: 0.9758\n",
      "Epoch 7/10\n",
      "1398/1398 [==============================] - 438s 313ms/step - loss: 0.0496 - accuracy: 0.9826 - val_loss: 0.0668 - val_accuracy: 0.9752\n",
      "Epoch 8/10\n",
      "1398/1398 [==============================] - 380s 272ms/step - loss: 0.0485 - accuracy: 0.9796 - val_loss: 0.0654 - val_accuracy: 0.9624\n",
      "Epoch 9/10\n",
      "1398/1398 [==============================] - 295s 211ms/step - loss: 0.0477 - accuracy: 0.9756 - val_loss: 0.0630 - val_accuracy: 0.9805\n",
      "Epoch 10/10\n",
      "1398/1398 [==============================] - 305s 218ms/step - loss: 0.0469 - accuracy: 0.9749 - val_loss: 0.0643 - val_accuracy: 0.9655\n"
     ]
    }
   ],
   "source": [
    "rnn_model = model.fit(data,\n",
    "                      target_classes,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation for training data\n",
    "\n",
    "#### Average ROC_AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9826446361220923\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(data)\n",
    "aucs = []\n",
    "for j in range(6):\n",
    "    auc = roc_auc_score(target_classes[:,j], p[:,j])\n",
    "    aucs.append(auc)\n",
    "print(np.mean(aucs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text\n",
       "id                                                                 \n",
       "00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test = pd.read_csv('tc_test.csv',index_col=0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add 6 detection_classes columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['toxic'] = '0'\n",
    "test['severe_toxic'] = '0'\n",
    "test['obscene'] = '0'\n",
    "test['threat'] = '0'\n",
    "test['insult'] = '0'\n",
    "test['identity_hate'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_test = test['comment_text'].values\n",
    "detection_classes = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']\n",
    "target_classes_test = test[detection_classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of the comments 5000\n",
      "Minimum length of the comments 1\n",
      "Median length of the comments 169\n"
     ]
    }
   ],
   "source": [
    "# Max and Min Length\n",
    "print(f'Maximum length of the comments {max(len(s) for s in comments_test)}')\n",
    "print(f'Minimum length of the comments {min(len(s) for s in comments_test)}')\n",
    "\n",
    "# Median Length\n",
    "s = sorted(len(s) for s in comments_test)\n",
    "print(f'Median length of the comments {s[len(s) // 2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_test = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer_test.fit_on_texts(comments_test)\n",
    "sequences_test = tokenizer.texts_to_sequences(comments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 182361 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_to_index_test = tokenizer_test.word_index\n",
    "print('Found %s unique tokens.' % len(word_to_index_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (89186, 100)\n"
     ]
    }
   ],
   "source": [
    "data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'toxic': r[:, 0], 'severe_toxic': r[:, 1], 'obscene': r[:, 2], \n",
    "                        'threat': r[:, 3], 'insult': r[:, 4], 'identity_hate': r[:, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['id'] = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasettt = dataset[['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.995326</td>\n",
       "      <td>0.387035</td>\n",
       "      <td>0.965221</td>\n",
       "      <td>0.207557</td>\n",
       "      <td>0.914302</td>\n",
       "      <td>0.454665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.000268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.009769</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89181</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.695490</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.136020</td>\n",
       "      <td>0.001467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89182</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.052134</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89183</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89184</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89185</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.979357</td>\n",
       "      <td>0.094307</td>\n",
       "      <td>0.893105</td>\n",
       "      <td>0.008470</td>\n",
       "      <td>0.766546</td>\n",
       "      <td>0.016893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89186 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0      00001cee341fdb12  0.995326      0.387035  0.965221  0.207557  0.914302   \n",
       "1      0000247867823ef7  0.004953      0.000138  0.002658  0.000066  0.002209   \n",
       "2      00013b17ad220c46  0.004423      0.000347  0.002000  0.000391  0.001979   \n",
       "3      00017563c3f7919a  0.002181      0.000035  0.000692  0.000062  0.000572   \n",
       "4      00017695ad8997eb  0.009769      0.000237  0.002650  0.000452  0.001575   \n",
       "...                 ...       ...           ...       ...       ...       ...   \n",
       "89181  fffcd0960ee309b5  0.695490      0.005379  0.329502  0.002649  0.136020   \n",
       "89182  fffd7a9a6eb32c16  0.052134      0.000403  0.004151  0.002140  0.007686   \n",
       "89183  fffda9e8d6fafa9e  0.001831      0.000027  0.000516  0.000066  0.000628   \n",
       "89184  fffe8f1340a79fc2  0.000683      0.000037  0.000164  0.000532  0.000233   \n",
       "89185  ffffce3fb183ee80  0.979357      0.094307  0.893105  0.008470  0.766546   \n",
       "\n",
       "       identity_hate  \n",
       "0           0.454665  \n",
       "1           0.000268  \n",
       "2           0.000210  \n",
       "3           0.000031  \n",
       "4           0.000065  \n",
       "...              ...  \n",
       "89181       0.001467  \n",
       "89182       0.000590  \n",
       "89183       0.000104  \n",
       "89184       0.002270  \n",
       "89185       0.016893  \n",
       "\n",
       "[89186 rows x 7 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasettt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasettt.to_csv(r'dataframe.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
